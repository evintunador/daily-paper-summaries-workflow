In this paper, the authors introduce AMIE (Articulate Medical Intelligence Explorer), an AI system optimized for diagnostic dialogue in medicine. AMIE is based on a large language model (LLM) and is designed to engage in natural, diagnostically useful conversations with patients. The goal is to improve access to diagnostic and prognostic expertise, enhance the quality and consistency of care, and ultimately improve health outcomes.
`
To develop AMIE, the authors used a diverse set of real-world datasets, including multiple-choice medical question-answering, expert-curated long-form medical reasoning, electronic health record (EHR) note summaries, and large-scale transcribed medical conversation interactions. These datasets were used to train AMIE on various medical tasks, such as medical reasoning, question answering, and summarization.

To address the limitations of real-world data, the authors also developed a simulated dialogue learning environment for AMIE. This environment allows AMIE to engage in self-play, where it interacts with an AI patient agent and receives feedback from a critic agent. This iterative self-improvement process helps AMIE refine its behavior and learn from a wide range of medical conditions and contexts.

To evaluate the performance of AMIE, the authors conducted a randomized, double-blind crossover study with primary care physicians (PCPs) and validated patient actors. The study involved text-based consultations with 149 case scenarios, and AMIE was compared to PCPs in terms of history-taking, diagnostic accuracy, management reasoning, communication skills, and empathy. The evaluations were done by specialist physicians and patient actors.

The results of the study showed that AMIE demonstrated greater diagnostic accuracy and superior performance on multiple evaluation axes compared to PCPs. Specialist physicians and patient actors rated AMIE as superior on most evaluation axes, indicating that AMIE has the potential to outperform human clinicians in diagnostic dialogue.

However, it is important to note that this research has limitations. The study used a text-chat interface, which may not fully represent the usual clinical practice. Further research is needed before AMIE can be translated to real-world settings. Nonetheless, the results represent a significant milestone towards the development of conversational diagnostic AI.

In summary, this paper presents AMIE, an AI system optimized for diagnostic dialogue in medicine. The authors demonstrate the effectiveness of AMIE in a comparative study with PCPs and highlight its potential to improve access to diagnostic expertise and enhance the quality of care.

Prerequisite knowledge:
- Understanding of artificial intelligence (AI) and machine learning concepts
- Familiarity with large language models (LLMs) and their applications
- Basic knowledge of clinical medicine, including history-taking and diagnostic reasoning
- Understanding of medical question-answering and summarization tasks

Citation:
Tao Tu, Anil Palepu, Mike Schaekermann, Khaled Saab, Jan Freyberg, Ryutaro Tanno, Amy Wang, Brenna Li, Mohamed Amin, Nenad Tomasev, Shekoofeh Azizi, Karan Singhal, Yong Cheng, Le Hou, Albert Webson, Kavita Kulkarni, S. Sara Mahdavi, Christopher Semturs, Juraj Gottweis, Joelle Barral, Katherine Chou, Greg S. Corrado, Yossi Matias, Alan Karthikesalingam, and Vivek Natarajan. "Towards Conversational Diagnostic AI." arXiv preprint arXiv:2401.05654 (2024).