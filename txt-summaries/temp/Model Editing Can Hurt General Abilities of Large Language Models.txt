This paper investigates the impact of model editing on the general abilities of large language models (LLMs). Model editing involves modifying the factual knowledge stored in LLMs to update their behavior without retraining. While model editing can improve the factuality of LLMs, this study raises concerns about potential side effects on the general abilities of LLMs.
`
The paper evaluates four popular model editing methods on two representative LLMs across eight task categories. The methods are assessed based on their efficacy, generalization, and locality in editing performance. The results show that while model editing improves factuality, it significantly impairs the general abilities of LLMs across various tasks.

The paper argues that the pursuit of improving factuality should not come at the cost of compromising the general abilities of LLMs. It calls for more research efforts to minimize the loss of general abilities during model editing and preserve them during the editing process.

The findings of this study have implications for the sustainable development of LLMs. It highlights the need to balance improvements in factuality with the preservation of general abilities in order to ensure the effectiveness and adaptability of LLMs in real-world applications.

Potential critiques of this study could include the limited scope of the evaluated editing methods and the specific LLMs used. Further research is needed to explore a wider range of editing methods and LLM architectures to validate the findings. Additionally, the paper does not provide specific recommendations for minimizing the loss of general abilities during model editing, leaving room for future investigations in this area.

- Knowledge of large language models (LLMs) and their training process
- Understanding of model editing and its purpose in updating factual knowledge in LLMs
- Familiarity with the concepts of efficacy, generalization, and locality in evaluating model editing methods
- Knowledge of the Transformer architecture and its components, such as self-attention and feed-forward networks
- Understanding of downstream tasks in natural language processing, including reasoning, natural language inference, question answering, dialogue, summarization, named entity recognition, and sentiment analysis

Citation: Gu, J.-C., Xu, H.-X., Ma, J.-Y., Lu, P., Ling, Z.-H., Chang, K.-W., & Peng, N. (2024). Model Editing Can Hurt General Abilities of Large Language Models. arXiv preprint arXiv:2401.04700.