In this paper, the authors propose a new framework called MeTA (Multi-source Test Time Adaptation) for adapting multiple pre-trained models to new test data distributions in an unsupervised manner. The goal is to combine the strengths of multiple source models to achieve better performance than any single source model. MeTA has two main components: learning the optimal combination weights for the source models and updating the model parameters based on the current test data.
`
To learn the combination weights, MeTA uses an optimization approach that minimizes the expected Shannon entropy of the weighted pseudo-labels generated by the source models. This ensures that the combination weights are chosen in a way that minimizes the test error on the current batch of test data. The authors also propose strategies for initializing the weights and selecting an optimal learning rate to speed up convergence.

Once the combination weights are determined, MeTA selects the most relevant source model based on the highest weight and updates its parameters using state-of-the-art single source test time adaptation methods. This ensures that the model is adapted to the current test data distribution and maintains good performance on the source domains.

The authors provide theoretical insights on how MeTA selects the best source model by optimizing the trade-off between model accuracy and domain mismatch. They show that MeTA aims to minimize the difference between the target population risk and the optimal population risk obtained by choosing the best combination weights.

The authors evaluate MeTA on diverse benchmark datasets and demonstrate that it achieves performance on par with the best-performing source model and mitigates catastrophic forgetting in dynamic test data distributions. They compare MeTA to existing adaptation methods and show that it outperforms them in terms of adaptation accuracy and robustness to forgetting.

One potential critique of MeTA is that it requires multiple pre-trained source models, which may not always be available or practical to obtain. Additionally, the optimization process for learning the combination weights may be computationally expensive, especially for large-scale datasets.

The implications of MeTA are significant as it provides a framework for effectively combining multiple source models during test time adaptation. This can be particularly useful in dynamic environments where the test data distribution changes over time. MeTA has the potential to improve the performance and robustness of models in real-world applications where adaptation to new data distributions is crucial.

- Unsupervised domain adaptation methods
- Test time adaptation methods
- Deep neural networks and their training process
- Batch normalization
- Optimization techniques for learning combination weights
- Evaluation metrics for model performance

Citation: Ahmed, S. M., Niloy, F. F., Raychaudhuri, D. S., Oymak, S., & Roy-Chowdhury, A. K. (2024). MeTMulti-source Test Time Adaptation. arXiv preprint arXiv:2401.02561.