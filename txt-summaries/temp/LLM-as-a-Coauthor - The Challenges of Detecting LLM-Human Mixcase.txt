In this research, the authors address the challenges of detecting mixcase, a hybrid text form that involves both machine-generated and human-generated content. They argue that current research on machine-generated text (MGT) detection predominantly focuses on pure MGT and human-written text (HWT), without adequately addressing the mixed scenarios of mixcase. To fill this gap, the authors introduce MIXSET, the first dataset dedicated to studying mixcase scenarios.
`
MIXSET is constructed by applying various editing operations to both HWT and MGT. These operations include AI-revised operations such as polish, complete, and rewrite, as well as human-revised operations such as humanize and adapt. The authors carefully select HWT and MGT datasets as the base data and perform manual annotations and evaluations to ensure the quality of MIXSET.

The authors conduct experiments to evaluate the efficacy of popular MGT detectors on MIXSET. They evaluate both metric-based and model-based detectors in binary and three-class classification settings. The experiments aim to answer several research questions, including the performance of current detectors on mixcase, the performance of detectors retrained on MIXSET, the generalization ability of detectors on mixcase, and the impact of training set size on detection ability.

The results of the experiments reveal several important findings. In Experiment 1, the authors find that existing detectors struggle to identify mixcase as a separate class or MGT, particularly in dealing with subtle modifications and style adaptability. In Experiment 2(a), the authors show that fine-tuning detectors on MIXSET improves their performance in classifying mixcase as MGT. In Experiment 2(b), the authors demonstrate that treating mixcase as a separate class in a three-class classification task leads to improved detection performance. In Experiment 3, the authors analyze the generalization ability of detectors on mixcase and find that some detectors perform well on mixcase from different editing operations and LLMs. In Experiment 4, the authors investigate the impact of training set size on detection ability and find that increasing the size of the training set improves detection performance.

The implications of this research are significant. The findings highlight the urgent need for more fine-grained detectors tailored for mixcase, as existing detectors struggle to accurately classify mixcase as MGT. The research also provides valuable insights for future research in the field of MGT detection, particularly in addressing the challenges posed by mixcase scenarios. The MIXSET dataset serves as a valuable resource for further exploration and development of detection methods for mixcase.

One potential critique of this research is the limited size of the MIXSET dataset. While the authors have carefully constructed the dataset and performed manual evaluations, a larger dataset could provide more comprehensive insights and improve the generalizability of the findings. Additionally, the evaluation of detectors in this research focuses on binary and three-class classification settings, and further investigation into other classification settings could provide a more complete understanding of detector performance.

In conclusion, this research sheds light on the challenges of detecting mixcase and provides valuable insights into the performance, robustness, and generalization ability of current detectors. The findings underscore the need for more fine-grained detectors tailored for mixcase and offer important implications for future research in the field of MGT detection.

- Large Language Models (LLMs)
- Machine Generated Text (MGT)
- Human Written Text (HWT)
- MGT detection methods
- Metric-based methods
- Model-based methods
- Dataset construction
- Mixcase
- MIXSET dataset
- Editing operations (polish, complete, rewrite, humanize, adapt)
- Binary classification
- Three-class classification
- Detector evaluation
- Generalization ability
- Training set size impact

Citation: Gao, C., Chen, D., Zhang, Q., Huang, Y., Wan, Y., & Sun, L. (2024). LLM-as-a-Coauthor: The Challenges of Detecting LLM-Human Mixcase. arXiv preprint arXiv:2401.05952.